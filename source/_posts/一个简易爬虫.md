---
title: 简单的python爬虫
description: 基础爬虫知识
data: 2023-6-24
updata: 2023-6-24
tags: 
  - 爬虫
categories:
  - python
---

### 一、requests.get()

##### ①安装requests库

​       windows电脑命令提示符为

```c
pip install requests
```

##### ②requests库的作用

​       requests库可以帮助我们下载网页源代码、文本、图片，甚至是音视频。本质是向服务器发送请求并得到相应

##### ③requests库使用

```python
import requests
#在使用前需要先通过 import 来引入 requests 库
res = requests.get('URL')
#我们通过调用requests库中的get()方法来获取数据，这个方法需要一个参数，这个参数就是你需要请求的网址。当请求得到「响应」时，服务器返回的数据就被赋值到 res 这个变量上面
```

​        requests.get 是在调⽤requests库中的get()⽅法，它向服务器发送了⼀个请求，括号⾥的参数是你需要的数据所在的⽹址，然后服务器对请求作出了响应。我们把这个响应返回的结果赋值在变量res上。

### 二、Response对象常用属性

|         属性         |           作用           |
| :------------------: | :----------------------: |
| response.status_code |     检查请求是否成功     |
|   response.content   | response对象的二进制数据 |
|    response.text     | sesponse对象的字符串数据 |
|  response.encoding   |    response对象的编码    |

下位状态响应码以及解释

| 响应状态码 |    说明    | 例子 |    例子说明    |
| :--------: | :--------: | :--: | :------------: |
|    1xx     |  请求接收  | 100  |  继续提供请求  |
|    2xx     |  请求成功  | 200  |    请求成功    |
|    3xx     |   重定向   | 305  | 应使用代理访问 |
|    4xx     | 客户端错误 | 403  |    禁止访问    |
|    5xx     | 服务器错误 | 503  |   服务不可用   |

1. **response.content**

   把Response对象内容以二进制数据的形式返回，适用于图片、音频、视频下载

2. **response.text**

   将response.content的二进制数据转换为字符串，适用于文字或者是网页源代码的下载

3. **response.encoding**

   能帮助我们定义Response对象的编码

### 三、爬虫规范

##### Robots 协议

​      Robots 协议是互联⽹爬⾍的⼀项公认的道德规范，它的全称是“⽹络爬⾍排除标准”（Robots exclusion protocol），这个协议⽤来告诉爬⾍，哪些⻚⾯是可以抓取的，哪些不可以。

##### 协议查看

1. 在网站的域名后面加上robot.txt就可以了。比如淘宝的Robot协议（https://www.taobao.com/robots.txt）
2. 协议里面最常见的英文是Allow和Disallow，Allow代表可以被访问，Disallow则代表禁止被访问

### 四、爬虫实践

我们下面将进行一个简单的爬虫的编写，首先我们确定目标

1. 目标网站：https://movie.douban.com/chart
2. 网站协议：https://movie.douban.com/robots.txt（⽬标⽹站 + robots.txt 可查看⽬标⽹站的⻚⾯爬取许可）
3. 爬取目标：爬取电影名、URL、电影基本信息和电影评分信息。

##### 过程分析

1. 确定数据位置、

   - 电影名、电影基本信息和电影评分信息详情⻚、URL均在 html ⻚⾯上；
   -  获取数据⽤ requests.get() ；
   - 解析数据⽤ BeautifulSoup

2. 提取数据（以当前网站为例）

   - 在⽹⻚的空⽩处点击右键，然后选择“检查”（快捷⽅式是ctrl+shift+i），再在 Elements ⻚⾯按 ctrl+f；
   - 点击【检查】⻚⾯左上⻆的 “⿏标” 按钮，再点击后右侧想要获取的内容可以定位到该内容对应的标签；
   -  如此，我们就定位到了电影名的所在位置，a标签内的文本，甚至还顺带找到了详情页URL的所在位置。如上图，a标签里有属性href，其值是https://movie.douban.com/subject/27010768/。点击它，你会跳转到这部电影的详情页：
   - 所以到时候，我们可以去提取a标签。接着，先用text拿到它的文本，再使用[href]获取到URL。
   - 以此网站为例，当我们的光标放在P标签上时，这个P标签包含了某部电影的所有基本信息
   - 这些都是p标签里的纯文本。这个p标签的属性是class="pl"
   - 根据电影名、URL、电影基本信息和电影评分信息的路径，我们可以知道这四者的最小共同父级标签是：div class="pl2"。

   ##### 代码实现

   爬取豆瓣top250电影评分

   ```python
   import requests
   from bs4 import BeautifulSoup
   
   url = 'https://movie.douban.com/top250'
   headers = {
       'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
   response = requests.get(url, headers=headers)
   soup = BeautifulSoup(response.text, 'html.parser')
   
   movies = soup.find(class_='grid_view').find_all('li')
   for movie in movies:
       title = movie.find(class_='title').string
       rating = movie.find(class_='rating_num').string
       print(title, rating)
   
   ```

这个程序会向豆瓣电影 Top250 的网页发送请求，然后使用 BeautifulSoup 库解析网页内容，获取电影名称和评分信息，并打印输出。